{"/":{"title":"alcaemre.com","content":"\nHello and welcome to Emre Alca's site! \n\nIf you are new here, I (Emre) would highly recommend you read my [[articles/mission-statement|mission statement]] so that you can have a decent idea of what I am about. To understand my approach to writing I would direct you towards my other meta-articles like [[articles/on-humility|On Humility]]. \n\n## Projects:\n### Doing vs. Being\nIn Cognitive Science at least, [[jargon/Functionalism|Functionalism]] has been the stance used to define minds for a long time--that to be a mind is to be capable of what minds do. Dretske says that mind must have the capacity to represent information, but also misrepresent information. Others say that a systesm must be able to attribute mental states, or perform some judgement of relevance realization (i.e. the intelligent ignoring of the vast majority of information) to be a mind. \n\n[Aman Bhargava](https://aman-bhargava.com/) and I have been considering another notion: what if functionalism is looking at the problem at the wrong level. Most minds that are discussed--be that human minds, animal minds, or the collective mind of an ant colony (an example I will often use)--[[jargon/emergence|emerge]] from the interactions between large populations of discrete parts. \n\nThe central intuition of this project is that any two systems that exhibit the same emergent behavior are comprised of parts that interact in ways that are described by analagous rules. That it is not the mental states that must have a functional lens put on them, but the neuron, or the ant.\n\nThe purpose of this project is to develop this stance, pulling from Philosophy of Mind, Mathematics and Computation, Shannon Information, Thermodynamics and Statistical Physics. \n\nAman and I believe that this notion holds true not only for the creation of minds, but the engineering of any [[jargon/Complex System|complex system]]. \n\u003e Articles:\n\u003e 1. [[articles/dvb-thesis|Doing vs. Being -- Understanding the Thesis]] (October 19, 2022). Introducing the idea of the [[jargon/homomorphism|homomorphism]] between emergent systems. The same patterns are present in seemingly very distinct organisms. Could the processes that make these similar patterns be analogous to one another?\n\u003e 2. [[articles/What You Must Keep, What You May Discard|What You Must Keep, What You May Discard]] (October 28, 2022). Philosophical discussion in the cognitive sciences about the level of emergence to go about analyzing cognition. Specifically, this discussion builds up to the idea of a multileveled ontology. This paper was an assignment for PHL342: *Minds and Machines* at the University of Toronto.\n\n\n\n\n\n\n\n\n\n\n","lastmodified":"2022-12-16T00:21:58.802377537Z","tags":null},"/articles/What-You-Must-Keep-What-You-May-Discard":{"title":"What You Must Keep, What You May Discard","content":"\n## Introduction\n\nDeveloping a theory, of any kind, in any field, is a non-trivial task. Developing a theory of mind is the most abstract of theoretical realms. I think that the abstractness of the mind demands a certain level of theoretical care. Physicists talk about a theory as a *[[jargon/homomorphism|homomorphism]]*--as a unidirectional map from the real world to a model one. In this model world, all the relevant relationships are maintained, and all other information is collapsed into a *kernel*. Some physicists say that the real work of being a theorist lies in the creation of the kernel. The larger your kernel is, the more elegant the theory, but also the more likely that some important relationship is missing. If the kernel is too large, the theory is clumsy and inefficient. Many physicists say that the true skill of a theorist is the ability to discern what you must keep and what you may discard. \n\nThis paper is concerned with the question \"is it possible for a non-human machine to believe the very same thing as you (i.e. to have a belief that has the same intentional content as one of your beliefs)?\" Specifically, the perspective of the [[jargon/Functionalism|Functionalists]], the Eliminative Materialists, and later in the paper, Daniel Dennett (who is particularly difficult to label--and probably quite proud of it). I believe the disagreements between these stances arises from their different kernels.\n\n## The Functionalist Stance\nThe Functionalists (with a capital 'F' as I may yet be a functionalist, but I know I am not a Functionalist) are interested in a computational metaphor for cognition. I think Fodor is quite clear himself when he says:\n\n\u003e\"An important tendency in cognitive science is to treat the mind chiefly as a device that manipulates symbols. If a mental process can be functionally defined as an operation on symbols, there is a Turing machine capable of carrying out the computation and a variety of mechanisms for realizing the Turing machine. (Fodor, 120)\"\n\nThis shows Fodor's true mission. The mental states can have intentional content or qualitative content. Qualitative content encompasses feelings (often referred to as 'what it is like'-ness) associated with an experience. Intentional content is propositional content--something that can be assigned a truth-value. Fodor is not concerned with qualitative content. He believes there are no causal relationships between the qualitative content of mental states. On the other hand, beliefs with intentional content have clear causal relationships. They have implications, they can build into larger arguments, they are the foundation of formal logic. Fodor thinks that the only structure we need to be interested in is the one that describes the relationships between the intentional content of beliefs--in the language of thought.\n\nDretske is a Functionalist who treats the argument with a little more sensitivity. He discusses what it means for a system to have intentional beliefs, and especially what it means for a system to have intentional beliefs of its own. Dretske uses the example of a compass. He says that a compass always represents some propositional content, even when there is no person looking at it. \"The intentional states a compass occupies do not depend on our explanatory purposes, attitudes, or stances\" (Dretske, 471). Even when the compass is stowed away in a pocket, it is still pointing north. To build up to the level of a system that not only represents intentional content, but can create representations with the same kind of intentional content that our representations have, Dretske builds up to a more thorough recipe:\n\n\u003e \"Our recipe yields a product having the following properties:\n\t\t\t1. The product has a propositional content that represents the world in an aspectual way (as, say, $F$ rather than $G$ even when $F$s are always $G$).\n\t\t\t2. This content can be either true or false.\n\t\t\t3. The product is a “player” in the determination of system output (thus helping to explain system behavior).\n\t\t\t4. The propositional content of this product is the property that explains the product’s role in determining system output. The system not only does what it does because it has this product, but what it is about this product that explains why the system does what it does is its propositional content.\n\t\t\t5. Though the system can behave stupidly, the normal role of this product (the role it will play when it is doing the job for which it was created) will be in the production of intelligent (need and desire satisfaction) behavior.\n\tThis, it seems to me, is about all one could ask of a naturalistic recipe for thought.\" (Dretske, 481)\n\nParts 1. and 2. are building up that this 'product' must be able to represent intentional content according to its most specific aspect (e.g. jersey cows are a category even though all jersey cows are cows). Part 3. speaks to how a system must have some natural function which informs its structure (e.g. the structure of the heart is informed by its function of pumping blood). Part 4. speaks to how the system must be able to genuinely misrepresent things in the world (e.g. an altimeter put in a vacuum chamber will think it is very high in the atmosphere, even if it is at sea level). Finally, 5. posits that a mental state must be able to interact with other mental states--to be capable of that Fodorian symbol operation. I think that Dretske has laid out a very clear account of what it is for a belief to have intentional content, but I do not see how these parts can be put together into something that has the kind of beliefs that humans do.\n\n## Two Bushes Trimmed to the Shape of Two Elephants\nIn Dennett's *Real Patterns*, there is a quote from Quine, that is quite tragically left to a footnote. Quine says:\n\n\u003e\"Different persons growing up in the same language are like different bushes trimmed and trained to take the shape of identical elephants. The anatomical details of twigs and branches will fulfill the elephantine form differently from bush to bush, but the overall outward results are the same.\" (Quine, 1960, 8)\n\nThis quote sums up my problem with both functionalism and Eliminative materialism. To look only at the shape of the bush from the outside misses the very important internal structure of branches and roots. We are not Laplace's demon, we cannot look only at the structure of the branches and roots and determine the overall shape. The kernel is too small or too big. The Eliminative Materialists keep too much, and the Functionalists keep too little.\n\nDennett thinks we need to be somewhere closer to the middle of this debate. He believes that mental states cannot be dispensed of, because we are looking to make a system that has mental states. Dennett proposes theory on the level of *intentions* (as in the seeking of goals, not the having of propositional content) as a reliable way of predicting behavior. This is because it allows us to detect the important relationships in the most efficient way--to develop a kind of 'folk psychology'. The intentional stance keeps what is necessary and discards the rest. \nDennett is also quite careful to say that while this is the right level to talk about the mind--to notice the interesting patters, it is not the level where the thoughts are happening. He says:\n\n\u003e\"The process that produces the data of folk psychology, we claim, is one in which the multidimensional complexities of the underlying processes are projected *through linguistic behavior*, which creates an appearance of definiteness and precision, thanks to the discreteness of words\" (Dennett, 45)\n\nDennett is more sympathetic to the idea that mental states are not explicitly things in the head, but something closer to \"indirect 'measurements' of a reality diffused in the behavioral dispositions of the brain (and body)\" (Dennett, 45). This is an idea that is originally from Churchland, and Dennett co-opts it quite carefully--he maintains that while the interesting action is not happening on the level of some 'language of thought', there is some pattern above the level of just sets of neurons firing. This is what he means when he says \"If the \"pattern\" is scarcely an improvement over the bit map, talk of eliminative materialism will fall on deaf ears—just as it does when radical eliminativists urge us to abandon our ontological commitments to tables and chairs.\" (Dennett, 51). \n\n## How Do We Find the Right Level For Analysis?\n\nI am quite sympathetic to Dennett's definition of prescription: a system has mental states when it can be best and most robustly described from the intentional stance--when it can be attributed beliefs and desires that reliably predict its behavior. But I'm still not quite satisfied. I am a kind of functionalist, I do believe that a non-human machine can have the same kind of mental states that we do (and not just beliefs with intentional content, but qualitative content as well). Animals are the first example--they clearly can have mental states even though they are non-human.\n\n![murmuration of starlings](images/7uUb.gif)\n\u003e Fig.1 A murmuration of starlings\n\nBefore returning to the discussion to the level of minds, I would like to point at a murmuration of starlings. I believe that if we make little robots that have similar physical constraints and similar goals (be that differential attractors or some other mechanism) to real starlings, they will, in some important sense, become starlings--and thus will make murmurations of their own. We do not need to know all the mechanics of all the birds, just the rules that describe their interactions with one another. When working with these [[jargon/emergence|emergent patters]], identifying the right level of interaction is very nontrivial. For the mind, the level of the cell, or the signal seems quite natural to me, but it still is at great risk of falling prey to Churchland's issue of not doing enough compression. And still, looking at too high of a level, something like the level of propositional attitudes seems like too great a leap. Dennett's notion of a multileveled ontology, to make changes at the low level to look at outcomes at the high level, seems quite promising to me.\n\n## References\n1. Churchland, PM. (1981). Eliminative Materialism And The Propositional Attitudes. The Journal of Philosophy.\n2. Dennett, DC. (1991). Real Patterns. The Journal of Philosophy.  \n3. Dretske, F. (1994). If You Can’t Make One, You Don’t Know How It Works. Midwest Studies in Philosophy.  \n4. Fodor, J. (1980). The Mind-Body Problem. Scientific American. \n5. Quine, WVO. (1960). Word and Object. MIT Press.","lastmodified":"2022-12-16T00:21:58.802377537Z","tags":null},"/articles/dvb-thesis":{"title":"Doing vs. Being -- Understanding the Thesis","content":"\n## What does *Doing vs. Being* Claim?\n\nThe purpose of this article is to understand what *Doing vs. Being* is claiming. Many of the details of this argument will have their own articles, where their nuances will be thoroughly explored.\n\nThe central claim of *Doing vs. Being* is that *if two systems display the same [[jargon/emergence|emergent]] behavior, they have a [[jargon/homomorphism|homomorphic relationship]].* This is a very non-trivial claim, which makes it difficult for me to call it a hypothesis or a theory. For now, it is just an intuition. I aim to explore its validity together with you, the reader, as it develops in these articles.\n\n## What is a Homomorphism?\nThe concept of a homomorphism was introduced to me by my nonlinear dynamics instructor. This was less of a technical introduction, but rather to motivate what it means to do physics. \nIf a physicist want to study some parts of the world, they must create some theory where the relationship between those parts are the same in the theory as they are in the world. The homomorphism is the structure preserving function that maps from theory to reality.\n\n![homomorphism figure](images/homomorphism.svg)\n\u003e Fig. 1: Consider a homomorphism $h$, which maps from $G$ to $H$. $h$ maps all possible $aN$ into $\\text{im}h$ (the image of $h$), maintaining the relationships between all $a$ in $aN$. All other parts of $G$ are collapsed into the *kernel* $(N=\\text{ker}h)$. [Image Source](https://en.wikipedia.org/wiki/Group_homomorphism) \n\nA very important feature of homomorphism in the kernel. The kernel contains all parts of reality that do not affect the relationships with which we are concerned. The real skill of a physicist, according to this particular instructor, is deciding what you must retain and what you may discard.\n\n## Homomorphic Relationships Between Physical Systems\n\nHomomorphic relationships do not only exist as maps between theory and reality. Seemingly very different physical systems can have a homomorphic relationship--they very often do. One of the first physics demonstrations I saw when I was young was the use of some weights and stretchy fabric to emulate gravity and orbital mechanics ([video](https://www.youtube.com/watch?v=MTY1Kje0yLg\u0026ab_channel=apbiolghs)). This is reasonable because the dynamics of a ball in a bowl on earth has a homomorphic relationship to orbits--they are both examples of motion in a central potential. This is an interesting mathematical exercise, but it does require a little bit of algebra, so it will be explored in its own small article.\n\n## Homomorphic Relationships Between Emergent Systems\n\nNow that we know what a homomorphism is, and that systems in nature can have homomorphic relationships, let's look back to an image from my [[articles/mission-statement|mission statement]]: Voronoi patterns emerging in seemingly very different situations.\n\n![voronoi-patterns](images/voronoi-patterns.png)\n\nThe *Doing vs. Being* hypothesis is that systems that exhibit the same emergent patterns have a homomorphic relationship to one another. The parts of the system that lead to this pattern are interacting in the same way--they have the same dynamics. \n\nThe Voronoi pattern is meant to be an illustrative example that is easy to understand, since the resemblance between these very different systems is striking, but it is also an isolated and weak case. The pattern only comes about in leaves in the sections between the structural skeleton, or only on the coat of a giraffe. This becomes more interesting and important when we look more directly at systems of competing and cooperating agents with more agency than just expanding until you reach the body of your nearest neighbor.\n\nTo say that these homomorphic relationships exist between emergent systems is to say that what makes an emergent pattern come about is not anything exclusive about the physical system, it is a product of the way the parts interact.\n\nIf we can make little robots that interact in the same way that ants do, would they self organize into a structure that is equivalent to an ant colony?\n\n## Doing vs. Being as a Method of Study\n\nIf this intuition does hold true (which I am still very skeptical of), it would greatly simplify the study of emergent systems. It would mean that any emergent system can be understood simply by finding the right set of rules that describe the way it interacts with its neighbours. If we could figure out the way that neurons interact with one another, and make a bunch of little neuronal robots, the same patterns that emerge in the brain would emerge here--or at least patterns that are described by the same dynamics. We would not need to re-engineer a neuron from scratch, only to understand the types of neurons and the way neurons interact with their neighbors.\n\nThis would effectively reduce the study of [[jargon/Complex System|complex systems]] to the study of the way that agents in populations interact with one another. The study of emergent systems becomes a field that is focused on cybernetics, information theory, and game theory. \n\nNaturally, it would follow that simple instantiations of emergent systems can be used as models or analog computers to simulate the dynamics of much more complex systems that exhibit the same emergent patterns.\n\nNow we have an understanding of what the *Doing vs. Being* argument is claiming. I have some real reservations that come from the way that it is a kind of [[jargon/Functionalism|functionalist perspective]]--similar to the one that inspired the language-based artificial intelligence projects of the 1980s and 1990s. The functionalist approach to artificial intelligence failed in some important ways. I'm excited to explore how these issues may affect the *Doing vs. Being* argument in an upcoming article.","lastmodified":"2022-12-16T00:21:58.802377537Z","tags":null},"/articles/mission-statement":{"title":"Mission Statement","content":"Sometimes I wonder what ancient humans thought as they looked at the motions of the stars--as they told their myths of gods and heroes immortalized in constellations.  These people were faced with patterns they could not help but notice, but had no way to describe--and thus all they could do was wonder and create stories. I can imagine the explanation we, today, have for these lights in the sky--that they are burning balls of gas unimaginable distances away--would feel as improbable to them as their description feels to us.\n\nA part of nature that seems to remain as mysterious as it was in ancient times is the realm of [[jargon/emergence|emergence]].\n\n![murmuration of starlings](images/7uUb.gif)\n\nThis is a murmuration of starlings--a flock of little birds. Each starling is entirely unaware of the incredible geometry made by the flock's collective motion. This is emergence--a physical population where the sum is properly greater than the sum of its parts--where the collective behaves in ways that could never be found in the individuals themselves.\n\nEmergent systems have a certain kind of magic to them. Once you are aware of their existence, emergent patterns become ever-present. Every living system, every mountain range--even the cracks that form in the drying of mud--exhibit emergent behavior. Often the same patterns appear in seemingly disparate places. The Voronoi pattern emerges in drying mud, the structure of dragonfly wings and leaves, as well as the camouflage patterns of giraffes.\n\n![voronoi patterns](images/voronoi-patterns.png)\nCan you describe this pattern? The presence of it is very clear, but what actually describes its structure? I find that emergent patterns always seem to be easy to notice, but are quite difficult to describe. They trigger the same pattern recognizing parts of the brain that have us find shapes in the clouds or constellations in the stars, but these patterns are real (or seem to be more real than constellations or cloud-shapes). They captivate wonder, but I don't think studying emergence will deromanticize them in the way that the placement of stars have been (in that any star being near any other in our sky is purely coincidental). \n\nStrangely enough, I was initially exposed to the concept of emergence in a course on philosophy of mind. The sense in which it was presented was:\n\n**\u003e If we assume there is no 'magic' to the mind, then consciousness must emerge from the interaction of neurons, similar to a tornado emerging from the interaction of warm and cool wind currents.**\n\nMost theories of mind in classical philosophy are dependent on some nonmaterial 'soul' or 'spirit' controlling the material body, making this approach seem very pragmatic and grounded in comparison. While the emergentist view of consciousness is based in science, it has been treated a lot like magic--just scientific magic. \n\nI was not so quickly satisfied.\n\nThe validity of the claim is obvious in the same way that the shape of the murmuration is obvious, but just because you can notice the pattern does not mean you can describe it. I began to look to methods of studying these emergent systems. The philosophy was sound, but this theory of emergence seemed to be the place in this argument that has the most room for growth. \n\nThe purpose of this cite is to give me a space to develop projects that have connections to many seemingly disparate parts, consider them on their own, and integrate them.\n\nThese projects often start with questions from Cognitive Science, but have effects that span Physics, Mathematics, Computation, as well as Sociology, Philosophy, and have the visceral beauty that is often only present in Visual Art.","lastmodified":"2022-12-16T00:21:58.802377537Z","tags":null},"/articles/on-humility":{"title":"On Humility","content":"\n## Why Did I Make This Site?\n\nIn the spring of 2020, I began to take the question 'how does mind emerge from matter' quite seriously. I was taking Prof. John Vervaeke's Introduction to Cognitive Science, and John is excellent at making convoluted discussions incredibly enticing. The question that was the most salient to me was not one of the necessary and sufficient conditions for mindedness, or the most simple functional form of cognition (although these are very interesting topics), it was *how mind emerges from matter.*\n\n\u003e There is nothing in an ant that describes the colony\n\nThe Cognitive Science program at the University of Toronto (UofT) has a very strong philosophical background and lots of support for students to explore cognition from a philosophical perspective. Professors Jim John and John Vervaeke are very approachable and very kind to their students. There is also significant access to work in artificial intelligence, as UofT is home to Geoffrey Hinton and the titanic Vector Institute. \n\nBut my central interest was not in philosophy or in computation. My interest is motivated by questions in both fields, but I am skeptical that the answers to those questions are likely to be answered be the contemporary approaches to these fields.\n\nMy central interest seemed to be in complex systems--in [[jargon/emergence|emergent systems]]. Systems where the whole is literally greater than the sum of its parts. There is nothing in an ant alone that describes the colony. The colony only exists as it emerges out of the interaction between thousands of ants. Prof. Vervaeke especially was happy to support and encourage this approach to cognitive science papers and more philosophical writing (which I am very grateful for), but I wanted to study emergence from a more empirical perspective. \n\nI put quite a lot of effort into considering what field I should study in alongside cognitive science to enable me to study emergent systems with my career. For the questions that I'm interested in, the most natural choice would be biology, but the truth of [Jsomers' *I Should Have Loved Biology*](https://jsomers.net/i-should-have-loved-biology/) dissuaded that approach.\n\nThe most natural next choice was physics. I tended to be sympathetic to the theories of mind that modelled cognition as a dynamical system--as a series of interacting feedback loops, like [Alicia Juarrero's *Dynamics in Action*](https://direct.mit.edu/books/book/3793/Dynamics-in-ActionIntentional-Behavior-as-a). \n\u003e\"Unlike the processes described by classical thermodynamics, which in their relentless march towards equilibrium forget their past, complex adaptive systems are essentially historical. They embody in their very structure the conditions under which they were created (including the chance events around which each self-organized stage reorganizes). The unrepeatable, random fluctuation or perturbation around which each phase of a sequence of adaptations nucleates leaves its mark on the specific configuration that emerges.\" (Juarrero, 9)\n\nJuarrero's book is really what convinced me to study physics. She was always working towards an Aristotelian metaphor for a kind of cognitive dynamics, but it was one of those theories that seem utterly obvious as the argument progresses--as if it was a tautology from its premises. I was convinced that the connection was more than metaphorical.\n\nTwo years (and some) later, and I have learned many very useful skills and very interesting concepts. My algebra is drastically improved, and I have a whole new lens of beauty for symmetry, for fluid dynamics, and for mathematical modelling in general. As thankful as I am for all of that, emergence has only ever been mentioned in my coursework once. It was with regard to the diffusion of molecules of a solute in some solvent as a collection of random walkers. Often when I mention emergence. I have struggled quite a bit to find supervisors and mentors in emperical complexity science. Of course, it is important to note that the COVID-19 pandemic has also made working with external professors much more difficult.\n\nAfter years of waiting, of learning and preparing to be able to empirically study the dynamics of complex systems, I have decided to make the opportunity to study these systems for myself. The purpose of this site is to house those explorations.\n\n## On Humility\nSince I am performing most of this study on my own, I need to be quite careful with regard to how I speak, as it must not be too authoritative. I will be exploring intuitions quite genuinely. I will likely find my intuitions to be incorrect, and that's a large part of the point. I want this site to be a record of my progression. I hope I often find my intuitions to be wrong, since that means I'm learning.\n\nI think there is something very interesting that comes with developing a concept, realizing its flaws, and iterating further. This iteration is a part of the scientific process that is not often highlighted. Writing about the ways that scientists are grossly wrong 10 times before coming upon a reasonable theory. I can only aim to exemplify and encourage this kind of healthy self-skepticim.\n\nAll of this is to say that I must approach this work with humility. That around all corners, I will likely be the fool. I hope that by the end of a project, I will be less of one. But to do this, I must also write with inegrity--with a clear sense of self-skepticism, absolutely--but I must explore and write about what my genuine intuitions are, and then change my positon in lew of new evidence.\n\nI can only hope that you, my reader, will come along for the ride--and perhaps join the discussion!","lastmodified":"2022-12-16T00:21:58.802377537Z","tags":null},"/drafts/Instrumentality-and-the-Extended-Mind":{"title":"Instrumentality and the Extended Mind","content":"\n\u003e This is the outline for a short presentation I gave on September 30, 2022 for PHY340: Issues in Philosophy of Mind at the University of Toronto, taught by Dr. Daniel Munroe\n\nIn [*The Extended Mind*](https://www.jstor.org/stable/3328150) Clarke and Chalmers argue that the tools that augment cognition are not only extensions of the mind, but should be regarded as a part of the mind itself. They use the example of a person playing Tetris™, who uses the the rotation of the shapes not to *position* the tetronimo, but to *determine* whether the tetronimo is compatible with a particular position. The rotation function of the game is *doing cognitive work* for the player. This determinative (i.e. cognitive, non-physical) action is referred to as an *epistemic* action--it aids and augments cognitive processes\". This is in contrast to *pragmatic* actions, which change things in the physical world. Clarke and Chalmers believe that epistemic actions deserve epistemic credit.\n\nThis is their notion of *active externalism*--that external cognitive processes are still cognitive, and should be considered a part of the mind. That a person connected with some external cognitive augmentation becomes a *coupled system* where the cognitive processes of the person become subject to the causes and constraints--the form--of the external system.\n\nMuch of their paper is concerned with address the issue that these coupled systesm may be too easily *decoupled*. Clarke and Chalmers try to resolve this issue by saying that the potential for decoupling does not damage the theory, since these external systems become a part of the mind when they become so reliably coupled to us that they become \"part of the package of cognitive resources that [we] bring to bear on the everyday world\" (11).\n\nClarke and Chalmers further support this claim with the notion of prosthetic memory. They describe Inga, who hears about an exhibition at the Museum of Modern Art (MoMA). Knowing that the MoMA is on 53rd Street, she walks there and visits the museum. They contrast Inga's experience with that of Otto, who has Alzheimer's disease. Otto has learned to use a notebook to act as the part of his cognitive system that stores information like the location of the MoMA. Otto may not know where to go to see this exhibition, but as long as Otto has his notebook to refer back to, he is just as capable of finding the MoMA as Inga is. Otto and his notebook, as a coupled system, are functionally equivalent (at least constrained to the task of navigating to the MoMA) as Inga is.\n\nThis notion of technology acting augmenting the mind, both in the sense of doing cognitive work and in altering the kind of work the mind can do, is all too familiar today. Smartphones act as a map, compass, encyclopedia, calculator, and the most sophisticated notebook coinceivable to Clarke and Chalmers in the 90's. The notion that cognition can be extended is all but irrefutable.\n\nWhere I struggle to follow Clarke and Chalmers is in the distinction between epistemic and pragmatic action. The article itself introduces these terms but sort of glosses over them. The example of epistemic action used is the Tetris player using the \"rotate\" function to see if a tetronimo fits in a particular place rather than performing the rotation mentally. Clarke and Chalmers' example of a pragmatic action is the plugging of a hole in a dam. These examples are not very helpful, so lets consider some new ones.\n\nLet's imagine a mathemetician who writes equations on a chalkboard to be able to track his algebra. Take the chalkboard away, and now the algebra is much more difficult. The chalkboard acts as a kind of prosthetic memory, augmenting the person's ability to do math. There is epistemic work being done by the chalkboard to aid in the doing of math--the act of holding the previous equation is an epistemic action.\n\nNow lets imagine carpenter who uses a hammer and nails and wood to build houses. There is pragmatic work being done by the nails that hold the pieces of the house together. \n\nThe issue that I have is that any pragmatic action is facilitated some epistemic action--the use of tools to do work is afforded by the  way that they extend the mind. The cliche even is 'when all you have is a hammer, everythign is a nail'. Tools change the way we interact with the world. That being said, I struggle to say that tools become a part of the mind when we use them, or use them so regularly that we feel as though we are missing something without them.\n\nIf we take away the hammer away from a craftsman, they cannot do their work. But have we removed a part of their body? I would hesitate to say yes.\n\nLet's go further. Say someone breaks their leg, and while their leg is in a cast, they must use crutches to walk. If we take away their crutches, have we taken away a part of their body? I would still hesitate to say yes.\n\nWhere it really gets muddy is when we speak of a person with a prosthetic limb. If we remove the limb, have we removed part of the body? In this case I would still hesitate to say yes, but I would be more sympathetic with the notion that we have.\n\nIf we say no to these points, how can we rightly say that we remove part of the mathematician's mind if we remove his chalkboard, or remove part of Otto's mind when we remove his notebook?\n\nAs I see it, there are prosthetics and there are augmentations. Prosthetics replace or offload existing cognitive functions. Augmentations afford new cognitive functions. I believe this is true regardless of whether the body or the mind is the thing that is being directly extended. The hammer acts as an extension of the arm when it is held, but it also afford the mind new methods of constructing physical structures. Therefore pragmatic actions are only afforded by the epistemic action of the tools that facilitate them.\n\nThis creates an important dilemmma. If Clarke and Chalmer's stance that epistemic actions deserve epistemic credit is maintained, then any distinction between the mind and world dissolves, and the distinction loses any meaning. On the other hand, the notion of extension cannot be eliminated. \n\nThis is the discussion question. Are prosthetics a part of the self? Where should we draw the line between mind an world? Between body and not-body","lastmodified":"2022-12-16T00:21:58.802377537Z","tags":null},"/drafts/computational-irreducibility":{"title":"Computational Irriducibility","content":"Coming soon, for now I defer to [wikipedia](https://en.wikipedia.org/wiki/Chaos_theory)","lastmodified":"2022-12-16T00:21:58.802377537Z","tags":null},"/drafts/eidos-and-form":{"title":"The Eidos: Forms and Essences","content":"\nComing soon, for now I defer to [wikipedia](https://en.wikipedia.org/wiki/Theory_of_forms)","lastmodified":"2022-12-16T00:21:58.802377537Z","tags":null},"/drafts/emergence-of-objects":{"title":"On the Emergence of Ontologies","content":"\u003eHow does sensory information become abstract thought?\n\nWhat is the physical phenomena that brings about abstract thought?\n\n  \n\nThis appears like an [[jargon/ontology|ontological]] question but it is rather the question of *the emergence of ontology itself*. This makes it not only a philosophical question, but a deep scientific question as well. \n\n  \n\nAs I have explored this question more and more, it has become increasingly clear that it demands a polymathic attitude. The parts are so disparite but so close. This project is meant to be a semi-formal exploration of the project of rigorously studying the emergence of ontologies. \n\n  \n\nI expect I will be wrong left right and center, and that my perspective will change as more work is done and as I am able to do more of my own work. Topics will be written about and returned to. The shape of the project will ebb and flow as we explore this magical snake that eats in own tail, as she crosses through philosophy, to biology, to physics, to computation, to sociology, to the art world and beyond. \n\n  \n\n  \n\nLet's begin this journey with a discussion of the [[maximally-presice-language|bounds of what we can study presicesly]].","lastmodified":"2022-12-16T00:21:58.802377537Z","tags":null},"/drafts/maximally-presice-language":{"title":"Edmund Husserl: What are We Able to Study Rigorously?","content":"\nThere is a powerful irony in our project. It is an attempt to formally study that which has historically eluded formal study. In his very funny [lecture on the legendary 20th century philosopher Edmund Husserl](https://youtu.be/y0sLHfcsPAA), Michael Sugrue describes the difference between the tradition of continental philosophy and that of anglo-americans is that the continental philosophers assume that the self is self-evident. \n\n\u003e...in progress..","lastmodified":"2022-12-16T00:21:58.802377537Z","tags":null},"/drafts/voronoi":{"title":"Building an Intuition: Why do Voronoi Patterns Emerge in so many different places?","content":"","lastmodified":"2022-12-16T00:21:58.802377537Z","tags":null},"/jargon/Complex-System":{"title":"Complex System","content":"A complex system has behavior that is [[jargon/emergence|emergent]] from its constituent parts","lastmodified":"2022-12-16T00:21:59.098376735Z","tags":null},"/jargon/Functionalism":{"title":"Functionalism","content":"\nFunctionalism is the notion that the hardware that a mental state runs on is not important, only the role it plays in the larger cognitive system is of consequence.","lastmodified":"2022-12-16T00:21:59.098376735Z","tags":null},"/jargon/chaos":{"title":"chaos","content":"Chaos is a high degree of sensitivity to initial conditions.\n\nTo read more see the backlinks or its definition and description in the article on [[computational-irreducibility|computational irreducibility]] ","lastmodified":"2022-12-16T00:21:59.098376735Z","tags":null},"/jargon/emergence":{"title":"Emergence","content":"Parts become whole. Emergence is when a population of agents have behaviour not present in their constituent parts.","lastmodified":"2022-12-16T00:21:59.098376735Z","tags":null},"/jargon/homomorphism":{"title":"homomorphism","content":"A unidirectional map that maintains the structure of a set of relationships while collapsing all other information into a kernel.\n","lastmodified":"2022-12-16T00:21:59.098376735Z","tags":null},"/jargon/self-organization":{"title":"Self-Organization","content":"This one topic is very big and very complicated. I'm very excited to get to it.","lastmodified":"2022-12-16T00:21:59.098376735Z","tags":null},"/lists/Music":{"title":"Music","content":"This page contains lists of records that I've listened to, and wanted to track my thoughts of, as well as a second list that holds records that I intend to listen to.\n\n# Have Listened\n- Burial: \n\t- Untrue\n- Tim Hecker:\n\t- Haunt me, Haunt me, Do it Again\n\t- Radio Amor\n\t- Mirages\n\n# To Listen\n- Coil\n\t- Musick to Play in the Dark","lastmodified":"2022-12-16T00:21:59.098376735Z","tags":null},"/notes/COG499/COG499-reading-list-notes":{"title":"COG499 Research Log","content":"\n## Erik Hoel\n\n1. Quantifying Causal emergence Shows that Macro Can Beat Micro (2013)\n2. Can Micro Beat Macro? Integrated Information Across Spatiotemporal scales (2016)\n3. Agent Above, Atom Below (2017)\n4. When the Map Is Better Than the territory (2017)\n5. What Caused What? An Irreducible Account of Actual Causation (2019)\n6. Uncertainty and Causal Emergence in Complex Networks (2019)\n7. Emergence of Informative Higher Scales in Biological Systems: a Computational Toolkit for Optimal Prediction and Control (2020)\n8. Emergence as Conversion of Information: A Unifying Theory (2021)\n\n\n\n## Michael Levin\n\n1. Emergence of Informative Higher Scales in Biological Systems: a Computational Toolkit for Optimal Prediction and Control (2020)\n2. [[notes/COG499/TAME|Technoloigcal Approach to Mind Everywhere: An Experimentally-Grounded Framework for Understanding Diverse Bodies and Minds]] (2022)\n\n## James Blachowicz\n\n1. The Essential Difference: Toward a Metaphysics of Emergence (2013)\n\n## Stephen Wolfram\n\n1. A New Kind of Science (2002)\n\n## Wolfgang Smith\n","lastmodified":"2022-12-16T00:21:59.098376735Z","tags":null},"/notes/COG499/TAME":{"title":"TAME","content":"# Technological Approach to Mind Everywhere: An Experimentally-Grounded Framework for Understanding Diverse Bodies and Minds\nMichael Levin (2022)\n\u003e [link to paper](https://www.frontiersin.org/articles/10.3389/fnsys.2022.768201/full)\n\n## Introduction\n\n- All cognitive agents are collective intelligences\n- cognition is not only self reflexive advanced cognition or metacognition, but also recognizes adaptive responsiveness and actions of different levels of sophistication\n\t- creates a continuum of cognitive sophistication, giving rise to an *axis of persuadability* \n\t- #### What is the axis of persuadability? What is its relationship with the intentional stance?\n\t\t- \"Persuadabilty refers to the type of conceptual and practical tools that are optimal to rationally modify a given system’s behavior.\" (4)\n\n## Cognition: Changing the Subject\n\n- \"The embodied nature of cognition means that mental Selves are dependent on a highly plastic material substrate which changes not only on evolutionary time scales but also during the lifetime of the agent itself.\" (5)\n\t- the Self is subject to significant change in real time\n\t- this can be slow, more ordinary change, or can be a more radical change in material (e.g. memories can be maintained from before and after the liquification of the caterpillar brain)\n- what are invariants that enable a self to persist?\n\t- Memories?\n\t\t- but memories can be transferred between individuals by way of brain tissue implants or other molecular engrams\n\t\t- memories are really communication between past and future Selves--biological bodies are made up of cells that die, are born and significantly rearrange, thus questions of how cognition can persist are questions of swarm dynamics rather than purely stable structures or programs\n\t- #### check back on [42; 43; 44; 45] for what sensory substitution is\n- Hybrots (hybrid robots and animals) plates of neurons can learn how to fly a flight simulator [53; 54; 55]\n\n## TAME: A Proposal For A Framework\n\n### Philosophical Foundations of an Approach to Diverse Intelligences\n\n1. a commitment to gradualism with respect to all important cognition-related properties\n\t- there is no true clear line that demarcates 'true cognition' from 'just physics'\n\t- example of issue: bilogically evolved froms have intrinsic motivation while software AI agents are only faking it *via functional performance*\n\t\t- but do fish or single cells or mitochondria *actually care*? \n\t- if we make hybrids of robots and cells how many cells does the system need before that living system's 'true' cognition extends to the whole system?\n2. There is no privileged material substrate for Selves\n\t- basel cognition (cognition in single cells, plants, animal tissues, swarm robotics) suggests the 'big vertabrate brain' is not a necessary condition for cognition\n\t- natural evolution is not the ony acceptable origin story form a true Agent \n\t- evolution is a blind hill climbing algorithm, with no understanding of how small scale changes influence large scale emergent outcomes. If this process can give rise to true minds, so can a rational engineering approach.\n3. The Measure of Agency is not a philosophical question. It is an empirical one.","lastmodified":"2022-12-16T00:21:59.098376735Z","tags":null},"/notes/PHL340-exam-prep":{"title":"PHL340 exam prep","content":"## PHY331\n\n7 Q\n6 points each\nformula sheet\nmultiple parts\n\nbiased towards second half of course\n- psets first\n- lectures next\n- then computationals\nwink wink nudge nudge chemical rate plots\n\n## PHL340\n- to study\n\t- treat study exam like a take home test\n\t- think critically about the content, like where to object\n## Artificial Intelligence and the Mind\n### What are the main theories of consciousness we encountered in the course?\n- what are the theories of consciousness\n\t- Block\n\t\t- Higher Order theory\n\t\t\t- a mental state is conscious when it has a higher order though\n\t\t\t- global workspace\n\t\t\t\t- a mental state is conscious when it is held in a global workspace that other subsystems of the mind can access\n\t\t- Dahane wants to integrate these two\n\t\t\t- when you lose either of these you also lose phenomenal consciousness\n\t\t- Block wants to reject both of these and argue for consciousness is a biological process\n\t\t\t- study the parts of the brain that give rise to consciousness to reduce consciousness to a physical process\n\t\t- Chalmers\n\t\t\t- property dualism\n\t\t\t\t- mental properties cannot be fully explained by physical properties\n\t\t- Descartes is a substance dualist\n\t\t\t- consciousness is distinct from the physical\n- **arguments??**\n### How can we know if an entity is conscious? What sorts of evidence do we have? Does our evidence differ for humans vs. computers? (readings directly discussing these Qs: Turing, Chalmers’ ch. 15).\n- Turing\n\t- behaviors: the Turing test\n- Chalmers hard problem\n\t- we don't just observe behaviors, we observe behaviors and see that they are correlated with our own consciousness\n\t-  its always possible that the other is a zombie, but this is not a bad inductive process for determining whether a thing is conscious\n\t\t- for computers we can only use behaviour and this is just weaker evidence\n\t- the most rigorous way for me to know whether a computer can have consciousness would be to upload my consciousness into a computer\n\t\t- how would one do this and ensure that they retain their consciousness?\n\t\t\t- chalmers says gradual uploading\n- **arguments???**\n## The Extended Mind Hypothesis\n### What is the Extended Mind Hypothesis? How do Clark and Chalmers argue for it by appealing to the Parity Principle?\n- Extended Mind Hypothesis\n\t- coupling\n\t\t- two systems are not closely coupled unless the external system is relied on as if it was an equivalent system internal to the human\n\t- parity principle\n\t\t- if a process is considered cognitive when it occurs in the head, it should be considered cognitive when it occurs outside the head\n\t- active externalism\n\t\t- if a process is considered cognitive when it occurs in the head, it should be considered cognitive when it occurspartially outside the head\n\t- The extended mind\n\t\t- if the mind is the cognitive apparatus, when a \n### What are Cognitive Offloading and Transactive Memory? How do these notions relate to the Extended Mind Hypothesis?\n- cognitive offloading\n\t- use of physical action to alter the information processing requirements of a task to reduce cognitive demand\n\t- there's something oxymoronic about calling this a 'reduction of cognitive demand' if the parts of the world that are being offloaded to are to be considered cognitive as well\n\t- can offload to the body or the world\n\t\t- you can count with your fingers\n\t\t- you can put information in a notebook\n- transactive memory\n\t- specific example of cognitive offloading\n\t- knowledge that is distributed across two or more individuals\n\t\t- human to human or human to object\n\t\t- the coupled system knows more than the person knows alone\n### What are Gertler’s two main objections to the Extended Mind Hypothesis? (one about introspection; one about people performing actions they didn’t actually perform).\n- Introspection\n\t- we can introspect our own mental states, but otto cannot introspect on his own notebook\n\t\t- introspection is inherently first-personal \n\t\t\t- as soon as more than one person can access your mental states, they are no longer-first personal\n\t\t\t\t- if mental states are made as the combination of qualitative and intentional content, then the correct first-personal account is only reconstructed when Otto is reading his notebook\n- Performing actions \n\t- if you program Otto's intentions into a robot (e.g. to make banana bread), and otto goes to sleep\n\t\t- show that this is counterintuitive\n\t\t\t- the crown is the king's will\n## Virtual Reality and the Mind\n### What does Chalmers mean when he says virtual worlds are just as “real” as physical reality? How does he draw a distinction between physical and digital objects?\n- objects in virtual worlds are not 'fictional objects' in the way that a sword from Lord of the Rings is. They are 'real objects'.\n- we can interact with them in the same way\n\t- we can perceive objects in virtual world in the same way as things in the world (we can see them)\n\t- we can manipulate them\n\t- they can affect us\n- Fictional objects are different\n\t- I cannot literally wield a sword from lord of the things in the actual world of the books\n\t- there is no way that I can interact with any object in the lord of the rings books that changes the way that characters act. They do the things that are written on the page no matter what *I* do\n\t- especially in a book rather than a movie \n- causal powers\n\t- what it is for something to be an object in the real world is for them to be able to interact with other objects\n\n### What is mind/body dualism, and why does Chalmers think virtual realities give rise to a form of mind/body dualism?\n- when hooked up to a virtual reality, you have a dualistic relationship to the body in the virtual world \n\t- the body in the virtual world is controlled by a thing not made of virtual substances\n- therefore, if it is plausible that we are living in a simulation (i.e. a virtual world) dualism itself is plausible\n\n\n### According to Ramirez et al., how do developers of VR simulations try to enhance empathy through “nudges”? How do Ramirez et al. appeal to the notion of semantic variance to argue that it’s impossible to know what it’s like to experience the world as someone very different from you?\n- VR simulations are for enhancing empathy through 'nudging'\n\t- a nudge is a feature of the environment that can shape behavior\n\t\t- must be subtle, not blatant, pushing for unconscious changes\n\t- Ramirez cares about educative nudges\n\t\t- especially towards understanding what It's like to be another person\n\t\t\t- especially marginalized populations: disabled people, people of colour, homeless people, but it is impossible to really understand what it is like to be another person\n\t\t\t\t- this is because of semantic variance\n\n- semantic variance\n\t- your past experiences dictate the way you interpret future events\n\t\t- if you have never experienced racial discrimination, the way you will interpret discriminatory experiences will be different than those who have experienced racial discrimination\n\n## Does Technology Manipulate Us?\n\n### What does Nguyen mean when he says Twitter gamifies communication and changes our communicative goals and values? \n(You should be able to explain Nguyen’s notions of value clarity and value capture, including some non-social media examples.)\n- value clarity\n\t- taking an activity that have complex goals and values and replacing them with quantified, simple values\n\t\t- the goal of going to school is to learn and understand things, but grades replace them with a score\n\t\t- twitter replaces the complex goals of communication with likes and retweets and replies\n\t\t\t- this replacement is a gamification of communication\n- value capture is the replacement of your complex values with the gamified values even outside of the game space (i.e. twitter)\n\n### In what sense does Munro think internet trolling is a kind of exploratory behaviour? How is this meant to explain why trolling behaviours tend to escalate and become increasingly extreme?\n(You should be able to explain the distinction between exploration and exploitation, including non-trolling examples of each. You should be able to explain Munro’s view about how trolls eschew the knowledge norm of assertion.)\n- exploration vs. exploitation\n\t- exploitation involves using existing knowledge to take advantage of known reward\n\t\t- high predictability of outcomes\n\t- exploration involves seeking new sources of reward\n\t\t- low predictability of outcomes\n\t\t- greater potential rewards in new forms of reward\n\t- this can happen in the social world\n\t- \n- when conversations act predictably, that's because they follow norms\n\t- e.g. knowledge norm of assertion\n\t\t- say true things\n\t- trolls violate the KNA to provoke emotional responses\n\t\t- this is a form of exploration to see how people would react to these surprising situations.\n\n### What does Madary mean when he claims our digital devices create illusions of agency, and how does he think such illusions arise?\n(You should be able to explain one or two specific examples of both digital and non-digital illusions of agency.)\n- Illusions of agency\n\t- agency: being in control of your actions\n\t- different from 'sense of agency' which is the feeling of being in control of your actions\n\t\t- usually these two go together\n\t- in illusions of agency, you have the sense of agency without actual agency\n\t- sense of agency occurs when there is predictability and fluency\n\t- there can be these things without actual agency\n\t- apps are designed to give a sense of agency while making their use as habitual and automatic as possible (i.e. removing agency)\n","lastmodified":"2022-12-16T00:21:59.098376735Z","tags":null},"/notes/PHY342-functionalism-paper-planning":{"title":"PHY342 functionalism paper planning","content":"# quotes\n## What is functionalism? \n\n- \"Functionalism is the philosophy of mind based on the distinction that computer science draws between a system's hardware, or physical composition, and its software, or program. The psychology of a system such as a human being, a machine or a disembodied spirit does not depend on the stuff the system is made of (neurons, diodes, or spiritual energy) but on how that stuff is organized. Functionalism does not rule out the possibility, however remote it may be, of mechanical and ethereal systems having mental states and processes.\" (Fodor, 118)\n- \"Functionalism is comitted to defining mental states in terms of their causes and effects\" (Fodor, 122)\n\n\n## According to functionalism, what are beliefs and desires?\n- Andrew in tutorial\n\t- To believe that B = to stand in a certain relationship to a mental symbol in your brain that stands for B.\n\t- Fodor thinks that cognition is the chugging though of symbol operations in the language of thought.\n- \"The traditional view in the philosophy of mind has it that mental states are distinguished by their having what are called either qualitative content or intentional content.\" (Fodor, 122)\n\t- Qualitative content is experiential content. If an image is viewed through a red filter and then a blue filter, something about how that experience *feels* changes.\n\t\t- Functionalism does not account for this, since there is seemingly no consistent causal relationship between input and qualitative experience\n\t\t\t- thus functionalism does not account for consciousness.\n\n## Can functionalism account for the intentional content of beliefs?\n- \"To say that a mental state has intentional content is to say that it has certain semantic properties.\" (Fodor, 122)\n\t-  \"There is at least one kind of thing other than a mental state that has intentional content: a symbol.\" (Fodor, 122)\n- Use Dretske\n\t- \"The idea behind this proscription of intentional ingredients seems to be that since what we are trying to build-a thought-is an intentional product, our recipe cannot use intentional ingredients.\" ... \"This, it seems to me, is a mistake, a mistake that has led some philosophers to despair of ever finding a naturalistic recipe for the mind.\" (Dretske 470)\n\t\t- intentional products are to the mind what copper is to an amplifier\n\t\t\t- \"What we are trying to understand, after all, is not intentionality, per se, but the mind. Thought may be intentional, but that is not the property we are seeking a recipe to understand.\" (Dretske 470)\n\t\t\t- \"Describing what such an instrument indicates is describing it in intensional terms. What one is describing is, therefore, in this sense, an intentional state of the instrument.\" (Dretske, 471)\n\t\t\t- \"The intentional states a compass occupies do not depend on our explanatory purposes, attitudes, or stances.\" (Dretske, 471) \n\t\t\t- \"Intentionality is a much abused word and it means a variety of different things. But one thing it has been used to pick out are states, conditions, and activities having a propositional content the verbal expression of which does not allow the substitution, salvu veritute, of co-refemng expressions.\" (Dretske, 471)\n\t\t- \n\n## Is it possible for a non-human machine to believe the very same thing as you. i.e. to have a belief that has the same intentional content as one of your beliefs?\n\n- \"An important tendency in cognitive science is to treat the mind chiefly as a device that manipulates symbols. If a mental process can be functionally defined as an operation on symbols, there is a Turing machine capable of carrying out the computation and a variety of mechanisms for realizing the Turing machine. (Fodor, 120)\"\n- \"Associating the semantic properties of mental states with those of mental symbols is fully compatible with the computer metaphor, because it is natural to think that a computer as a mechanism that manipulates symbols. A computation is a causal chain of computer states, and the links in the chain are operations on semantically interpreted formulas in a machine code. To think of a system (such as the nervous system) as a computer is to raise questions about the nature of the code in which it computes and the semantic properties of the symbols in the code. In fact, the analogy between minds and computers actually implies the postulation of mental symbols. There is no computation without representation\" (Fodor, 122)\n- \"For if one could concoct a recipe for building systems capable of misrepresentation-capable, that is, of saying of something that was not F that it was F-then one would have a recipe for meaning, for constructing structures having a content that was independent of causes in the desired sense\" (Dretske, 472)\n- \"What we would have is a naturalistic recipe for representation, a way of building something that would have, quite apart from its creator’s (or anyone else’s) purposes or thoughts, a propositional content that could be either true or false.\" (Dretske, 474)\n\n# Argument planning\n\n## Is it possible for a non-human machine to believe the very same thing as you. i.e. to have a belief that has the same intentional content as one of your beliefs?\n\n- The central claim of the functionalist project is that this is true\n\t- use 1.3.1 or 1.3.2 computation is cognition etc.\n\t- lets buildup Dretske's recipe and see if it is sufficient for creating cognition\n\t\t- \"Our recipe yields a product having the following properties:\n\t\t\t1. The product has a propositional content that represents the world in an aspectual way (as, say, $F$ rather than $G$ even when $F$s are always $G$).\n\t\t\t2. This content can be either true or false.\n\t\t\t3. The product is a “player” in the determination of system output (thus helping to explain system behavior).\n\t\t\t4. The propositional content of this product is the property that explains the product’s role in determining system output. The system not only does what it does because it has this product, but what it is about this product that explains why the system does what it does is its propositional content.\n\t\t\t5. Though the system can behave stupidly, the normal role of this product (the role it will play when it is doing the job for which it was created) will be in the production of intelligent (need and desire satisfaction) behavior.\n\t\tThis, it seems to me, is about all one could ask of a naturalistic recipe for thought. (Dretske, 481)\n\t- Let's step through each of these points and make sure we understand each of them, and see if they come together to answer our question.\n1. The product has a propositional content that represents the world in an aspectual way \n\t- The system we are concerned with must be able to construct mental representations (beliefs and desires) of things in the world in a way that has intentional content.\n2. This content can be either true or false.\n\t- represent information that can be assigned a truth value\n3. The product is a \"player\" in the determination of system output.\n\t- The system must posess some natural function\n4.  The propositional content of this product is the property that explains the product’s role in determining system output.\n\t- this is what Dretske means when he talks about how an altimiter uses air pressure to measure altitude, and thus by putting it in a sealed chamber of low pressure can genuinely misrepresent reality. \n\t- function is the relationship between \n5. The normal role of this product will be in the production of intelligent behavior\n\t- The system must have some rationality\n\nDretske says that any systems that has these things is capable of representation--capable of having beliefs that have the same kind of intentional content as ours, and has constructed that belief for itself.\n\n# Begin Essay:\n\n~~One of the central questions in cognitive science and in the philosophy of mind is the question of whether a non-human machine could be capable of having mental states, of having beliefs. The functionalist approach is that if we understand what functions lead to the having of beliefs, those functions, when instantiated in non-human systems, will still lead to the having of beliefs. Jerry Fodor, one of the titans of functionalism, says the functionalist stance says that \"[t]he psychology of a system such as a human being, a machine or a disembodied spirit does not depend on the stuff the system is made of (neurons, diodes, or spiritual energy) but on how that stuff is organized\" (122). The central claim of the functionalist view is that a non-human machine can have the same kind of beliefs (i.e. mental states) as a human, but they way they define those beliefs is what is most important. In this essay I will argue not that functionalism is wrong, but that the philosophers traditionally associated with the functionalist stance are looking at the wrong level of causality.\n\n## What do the functionalists mean by 'mental state' or 'belief'\n\n~~The form of functionalism of Fodor and Dretske looks at functions on the level of traditional philosophy of mind--which is only natural, as they are (surprisingly) philosphers of mind. And \"The traditional view in the philosophy of mind has it that mental states are distinguished by their having what are called either qualitative content or intentional content\" (Fodor, 118). The qualitative content of a mental state is experiental content, the way that something *feels*. Functionalism is not interested in qualitative content, as it seems to etheral for these strong naturalists--that qualitative content does not have clear causal relationships between mental states. After all \"[f]unctionalism is comitted to defining mental states in terms of their causes and effects\" (Fodor, 122), so they would have little concern of qualitative content. Intentional content on the other hand, that is the domain of functionalism. Intentionalism as Dretske and Fodor speak of it is the having of propositional content. What it means for a statement to have propositional content is that it can be assigned a value of 'true' or 'false' depending on the statement's validity.\n\n~~Dretske takes a thorough approach to describing what functions come together to have a thought or to have a mental state, describing a recipe for thought:\n\"Our recipe yields a product having the following properties:\n\t1. The product has a propositional content that represents the world in an aspectual way (as, say, $F$ rather than $G$ even when $F$s are always $G$).\n\t2. This content can be either true or false.\n\t3. The product is a “player” in the determination of system output (thus helping to explain system behavior).\n\t4. The propositional content of this product is the property that explains the product’s role in determining system output. The system not only does what it does because it has this product, but what it is about this product that explains why the system does what it does is its propositional content.\n\t5. Though the system can behave stupidly, the normal role of this product (the role it will play when it is doing the job for which it was created) will be in the production of intelligent (need and desire satisfaction) behavior.\nThis, it seems to me, is about all one could ask of a naturalistic recipe for thought.\"\" (Dretske, 481)\nWe will build up this argument by discussing each of these points individually, and once we are through, if they all hold valid, we will discuss if they come together to be sufficient for a naturalistic recipe for thought.\n\n## 1. The product has a propositional content that represents the world in an aspectual way\n~~This is Dretske saying that the system we are concerned with must be able to construct mental representations (beliefs and desires) of things in the world in a way that has intentional content. This kind of intentional content is not concerned with motivation or teleology, it is intentional as the having of propositional content. Specifically~~\n\n\n# Essay outline round 2\n## Is it possible for a non-human machine to believe the very same thing as you. i.e. to have a belief that has the same intentional content as one of your beliefs?\n\nThesis: There is more to having beliefs than being able to represent information using a structure that requires intentional content.\n\n\"Different persons growing up in the same language are like different bushes\ntrimmed and trained to take the shape of identical elephants. The anatomical details\nof twigs and branches will fulfill the elephantine form differently from bush to bush,\nbut the overall outward results are the same.\" Word and Object (Cambridge: MIT,\n1960), p, 8.\"\n\n## who are the functionalists and what do they think\n- Fodor and Dretske\n- \"Functionalism is comitted to defining mental states in terms of their causes and effects\" (Fodor, 122)\n- From the Functionalist stance, to believe that $B$ is to say that there ","lastmodified":"2022-12-16T00:21:59.098376735Z","tags":null},"/notes/PHY460-definitions":{"title":"PHY460 definitions","content":"# Overview\n## The importance of being nonlinear\n### phase space\n- the space where the axes are the parameters of a system of differential equations\n- we are interested in drawing trajectories when given a system\n### trajectory\n- a curve drawn by the solutions (say $(x_1, x_2)$) to system (say $(\\dot{x}_1, \\dot{x}_2)$) in phase space.\n- the curves are the show the dynamics of the system\n### $n$-dimentional system or $n$th-order system\n- a system is $n$-dimensional when it has the coordinates $x_1, x_2, ... , x_n$ and thus has an $n$-dimensional phase space\n- this $n$ determines the dimension of the phase space, and thus also the drawing\n### nonautonomous system\n- A nonautonomous system is a system that is explicitly time dependent\n- makes our equations partial differential equations\n# 1-D Flows\n## Flows on the line\n### one-dimensional or first order system\n- systems where $n=1$, expressed in the form of $\\dot{x} = f(x)$ where $f(x)$ cannot explicitly depend on $t$\n- archetypical system\n### flow\n- if $\\dot{x} \u003e0$ the flow is to the right\n- if $\\dot{x} \u003c 0$ the flow is to the left\n- allows us to characterize the behavior of a system\n### fixed points\n- occur when $\\dot{x} = 0$ \n### stable fixed points\n- occur when $\\ddot{x} \u003e 0$\n- AKA *attractors* or *sinks* \n- with a perturbation to the left, the system gets pushed back to the right, with a perturbation to the left, there is a push back to the left\n- all flows end at a stable fixed point or diverges to infinity\n\n### unstable fixed points\n- occur when $\\ddot{x} \u003c 0$ \n- AKA *repellers* or *sources*\n- any perturbation away from an unstable fixed point sends it to the nearest stable fixed point or out to infinity\n- all flows end at a stable fixed point or diverges to infinity.\n\n## Fixed Points and Stability\n### phase point\n- we take an arbitrary initial condition $x(t_0) = x_0$\n- this point is the phase point\n- we follow the flow from this point on a *phase portrait* to see how the particle behaves as $t \\rightarrow \\infty$\n### trajectory\n- the plot of the evolution of the *phase point* as $t \\rightarrow \\infty$ on the *phase portrait*\n- shows what stable point the *phase point* converges towards, or whether it diverges.\n### phase portrait\n- plot of $(t, x(t))$\n- shows all the qualitatively different trajectories of the system\n### equilibrium\n- represented by fixed points\n- if $x=x^*$ then $x= x^*$ for all time\n- A stable equilibrium are geometrically represented by stable fixed points\n## Population Growth\n### Logistic equation \n- take $N=$ current population, $r=$ growth rate, $K =$ Carrying Capacity  $\\dot{N} = rN \\left( 1 - \\frac{N}{K} \\right)$ And $N = N_0 e^{rt}$\n- models population growth\n- displays fractal bifurcation behavior\n### Carrying Capacity ($K$)\n- if  $N \u003c K$ the population keeps growing with the growth rate $r$\n- if  $N\u003eK$ the population starts decreasing.\n## Linear Stability analysis\n### Linearization about $x^*$ \n- $\\dot{\\eta} \\approx \\eta f'(x)$ where $\\eta = \\frac{d}{dt}(x-x^*) = \\dot{x}$ \n- any perturbation $\\eta(t)$ grows exponentially if $f'(x)\u003e0$ and decays if $f'(x)\u003c0$\n- if $f'(x) = 0$ the test is inconclusive, as this is the higher order terms of the Taylor series are not negligible \n- this allows us to determine the stability of fixed points algebraically\n### characteristic time scale\n- $\\tau=\\frac{1}{|f'(x^*)|}$ \n- $\\tau$ is the time required for $x(t)$ to vary dignificantly in the neighborhood of $x^*$ \n## Existence and uniqueness\n### Existence and Uniqueness theorem\n- we have the initial value problem $$\\dot{x} = f(x), \\ x(o) = x_0$$ If $f(x)$ and $f'(x)$ are continuous on an open interval $R$ of the $x$-axis, and that $x_0 \\in R$. Then the initial value problem has a solution $x(t)$ on some time interval $(-\\tau, \\tau)$ about $t=0$ and this solution is unique.\n- when the solution is not unique, we cannot use the geometric approach to analyzing the behavior of a particle. This is because the particle could move any of the possible ways\n## Impossibility of Oscillations\n### monotonicity\n- $\\dot{x} \\geq 0$ is always true or $\\dot{x}\\leq 0$ is always true\n- when approaching an equilibrium solution, the particle can never overshoot the mark, and damped osciallations can never happen\n### Over Damped Limit\n- for a mechanical system, say a spring that is in a highly viscous fluid, when preturbed, it will not oscillate, rather it will be pulled to an equilibrium point\n- this approach to an equilibrium point follows monotonicity\n## Potentials\n### Potential $V(x)$\n- defined as $$\\dot{x} =f(x) = - \\frac{dV}{dx}$$\n- $V(t)$ decreases along trajectories, and the system always moves towards a lower potential\n### equilibrium point\n- occur when $\\frac{dV}{dx} = 0$ and thus where $V(x)$ remains constant\n- the local minima of $V(x)$ correspond to stable fixed points\n- the local maxima of $V(x)$ correspond to unstable fixed points\n### Double-well potential or Bistable potential\n- a potential with two local minima of $V(x)$\n- a system with 2 stable equilibria\n## Solving Equations on the Computer\n### Euler's Method\n- numerical integration scheme which follows $$ x_{n+1} = x_n + f(x_n)\\Delta t $$\n- must start with some initial condition $x = x_0$ at $t=t_0$ and with a known $f(x)$\n### Error\n- $$ E = |x(t_n)-x_n| $$\n- this is the error in a single timestep.\n### Stepsize $\\Delta t$\n-  the amount of time between each step in a numerical integration\n- smaller $\\Delta t$ means a smaller error\n### Fourth-order Runge-Kutta method\n- thought of as the best compormise between minimizing error as well as compute time\n- First, four numbers are calculated $$ \\begin{split} k_1 \u0026 = f(x_n) \\Delta t \\\\ k_2 \u0026 = f(x_n + \\frac{1}{2} k_1) \\Delta t \\\\ k_3 \u0026 = f(x_n + \\frac{1}{2} k_2) \\Delta t \\\\ k_4 \u0026 = f(x_n +k_3) \\Delta t \\end{split}$$ and then $x_{n+1}$ is given by $$ x_{n+1} = x_n + \\frac{1}{6}(k_1 + 2k_2 + 2k_3 + k_4) $$\n### Round-off Error\n- the error inherent to computer calculations, also called *floating point error*\n### Slope Field\n- when solving systems numerically, the first thing we do is plot a slope field on the $(t, x)$ plane. \n- for each point on the plane, $dx/dt$ at that point is computed, and thus makes a field of slopes\n- Once we have ethe slope field, we can draw our trajectories from any initial condition, as governed by our slope field.\n# Bifurcations\n## Introduction to Bifurcations\n### Bifucations\n- changes in position or stability of fixed points\n- qualitative changes in dynamics\n### Bifurcation Points\n- values of the control parameter $r$ where a bifucation occurs\n- acts as a sort of critical point\n## Saddle-Node Bifurcations\n### Saddle-Node Bifurcation\n- Bifurcation where fixed points are created and destroyed\n- prototypically $\\dot{x} = r + x^2$\n- if $r\u003e0$  there are no fixed points\n- if $r = 0$ there is one semi-stable fixed point\n- if $r\u003c0$ there is one stable fixed point and one semi-stable fixed point\n### Bifurcation Diagram\n- plot of $(r, x)$ which shows for what values of $r$ there are bifurcations\n- plotted in parameter space\n- the shape of the plot on a bifurcation diagram allows for the classification of a bifurcaiton\n### Bifurcation curve\n- the plot on a bifurcation diagram is a bifurcation curve, representing the chagne in qualitative behavior in the parameter space\n### Normal Forms\n- protypical forms of a kind of bifurcation\n- representative of all examples of that bifurcation\n## Transcritical Bifurcation\n### Transcritical bifurcation\n- has the normal form $\\dot{x} = rx - x^2$\n- one fixed point always remains, but its stability changes, or rather, undergoes an exchange of stabilities\n### Exchange of Stabilities\n- for when there are two fixed points, and they swap stability after a bifurcation\n- usually goes from ($x_1^*$ stable, $x_0^*$ unstable) $\\rightarrow$ ($x_0^*$ semistable) $\\rightarrow$ ($x_0^*$ stable, $x_2^*$ unstable)\n## Pitchform Bifurcation\n### Symmetry\n- bitchfork bifurcations are found in problems that demonstrate a symmetry\n- fixed points appear in symmetrical pairs\n- if a pillar is to buckle under a certain load, it is as likely to buckle left as to buckle right, and thus has a symmetry\n### Supercritical Pitchform Bifurcation\n- Normal form $\\dot{x} = rx -x^3$ \n- for $r \\leq 0$ there is only one stable point at $x^* = 0$\n- for $r\u003e0$ there are 3 fixed points\n\t- one unstable fixed point at $x^*=0$ \n\t- two stable fixed points at $x^* = \\pm \\sqrt{r}$ \n### Critical Slowing Down\n- in a supercritical fixed point, when $r=0$ the clope of the $(\\dot{x}, x)$ graph is 0 at the fixed point $x^*=0$ \n- this means the solution no longer decays exponentially fast, resulting in a critical slowing down\n### Subcritical pitchfork Bifurcation\n- Normal form $\\dot{x} = rx - x^3$ \n- for $r \\leq 0$ there is only one unstable fixed point at $x^* = 0$\n- for $r\u003e0$ there are 3 stationary points\n\t- one stable fixed point at $x^*=0$ \n\t- two un stable points at $x^* = \\pm \\sqrt{r}$ \n- the actual canonical system of a subcritical pitchfork is $\\dot{x} = rx+x^3-x^5$\n### Symmetry Broken Solutions\n- the solution has less symmetry than the governing equation\n- this points at a fundamental change in dynamics\n### Characteristic Time Scale\n- RETURN TO, YOU DO NOT UNDERSTAND THIS\n### Cusp point\n- when there are two control parameters, $r, \\ h$ \n- occurs when two bifrucation curves meet tangentially on a stability diagram\n- this means two parameters must be tuned\n### Stability Diagram\n- show changes of behavior in parameter space\n### Cusp Catastrophe\n- RETURN TO, YOU DO NOT UNDERSTAND THIS\n# Linear Systems\n## Definitions and Examples\n### Two Dimensional Linear System\n- has the form $$\\begin{split} \\dot{x} \u0026 = ax + by \\\\ \\dot{y} \u0026 = cx + dy\\end{split}$$\n- can be rewrittten in the form of  $\\dot{\\vec{x}} = A \\vec{x}$ where $A = \\begin{pmatrix} a \u0026 b \\\\ c \u0026 d \\end{pmatrix}$ and $\\vec{x} = \\begin{pmatrix} x  \\\\ y \\end{pmatrix}$ \n- linear means that if $\\vec{x}_1$ and $\\vec{x}_2$ are solutions, then any linear combination of these $c_1 \\vec{x}_1 + c_2 \\vec{x}_2$ \n- the solutions to these DE's are trajectories in the phase space\n### Simple harmonic Oscillator\n- has form $m\\ddot{x} + kx = 0$\n- ","lastmodified":"2022-12-16T00:21:59.098376735Z","tags":null},"/notes/PHY460-definitions-and-important-theorems":{"title":"PHY460 definitions","content":"## 1-Dimensional definitions and Theorems\n### Generalization/reduction of order\n- reduction to a system of first-order differential equations $$\\frac{d}{dt} \\vec{x} = \\vec{f}(\\vec{x})$$ enables plotting in phase space\n- usually depends on a substitution of $y = \\dot{x}$ and solving for y\n### Existence \u0026 Uniqueness\n- $\\dot{x} = v(x)$ has a _unique_ solution around an initial condition $(t_0, x_0)$ provided the functions are smooth in the service of the _Lipschitz condition_ \n### Lipschitz Condition $[L]$\n-  $\\forall x, y \\in (a, b), |v(x) - v(y)| \u003c k |x-y|$ \n- this implies that $v(x)$ is continuous and a finite derivative exists almost anywhere $$ \\frac{|v(x)-v(y)|}{|x-y|}\u003ck, \\ k\\text{ being a finite number} $$\n- this effectively means that solutions reach a fixed point in finite time\n### Characteristic Time Scale\n- The characterisitic time scale is the time required for $x(t)$ to vary significantly from $x^\\*$ \n- the characteristic time scale is $\\frac{1}{f'(x)}$ calculated at $x^\\*$ \n### Bifurcation\n- quantitative change in behaviour\n\t- creation or destruction of fixed points\n\t- change in stability of fixed points\n### Saddle-node bifurcation\n- has the normal form $\\dot{x} = r + x^2$\n\t- when $r\u003e0$, no fixed points\n\t- when $r=0$, 1 fixed point (semi-stable)\n\t- when $r \u003c 0$, 2 fixed points (1 stable, 1 unstable)\n- fixed points appear and disappear\n### Transcritical Bifurcation\n- normal form: $\\dot{x} = rx-x^2$\n- one fixed point is maintained, but undergoes a change in stability. Another fixed point merges with the other (at $r=0$), and re-emerges out the other side, with the two fixed points having swapped stability\n### Subcritical pitchfork bifurcation\n- normal form: $\\dot{x} = rx + x^3 - x^5$ \n- one unstable fixed point becomes one stable and 2 unstable fixed points (mathematically)\n- physical systems have the $x^5$ higher order stabilizing term to avoid loss of generality, adding another two stable fixed points above and below the unstable ones, which can be jumped to exhibiting hysteresis\n### Hysteresis\n- Hysteresis is when, in a case of a subcritical pitchfork bifurcation, a particle leaves the origin after it is stable to either the positive or negative branch. If the control parameter is adjusted such that the origin regains stability, for some range of the parameter, it stays on its new branch until that branch loses stablity itself.\n### Supercritical Pitchfork bifurcation\n- normal form: $\\dot{x} = rx-x^3$\n- a stable fixed point splits into an unstable fixed point and two stable fixed points\n- describes second order (gradual) phase transitions\n### Nondimensionalization\n- This is the substitution $t=T\\tau$ where $\\tau$ is the dimensionless time and $T$ is the characteristic timescale\n- the nondimensionalized system makes relationships easier to notice, since it reduces the number of parameters we need to be concerned with, and can identify those individual parameters later\n## 2-Dimensional Stability\n### 2-dimensional system\n- system of differential equations $$\\begin{cases}\n  \\dot{x} \u0026= f(x,y) \\\\\n  \\dot{y} \u0026 = g(x,y)\n  \\end{cases}$$\n### phase plane\n- the plane made by $(x,y)$\n### Nullcline\n- where $\\dot{x}=0$ or $\\dot{y} = 0$ \n- includes nullclines, which are lines where one variable has time progression and the other doesn't\n### Fixed points\n- a point where $(\\dot{x}, \\dot{y}) = (0,0)$\n- i.e. there is no time progression\n### Phase Portrait\n- graph of the overall trajectories in phase space (not all trajectories, just the qualitatively demonstrative ones)\n### Closed Orbit\n- a trajectory that circulates around a fixed point and back on itself\n- for any initial point on the trajectory $\\vec{x}_0$, for some time $t$, the trajectory will return to $\\vec{x}_0$ \n### Liapunov Stable\n- all trajectories sufficiently close to a fixed point $\\dot{\\vec{x}}$ remain sufficiently close for all time\n### Linear Stability analysis of a fixed point in 2-Dimensions\n- Found by finding the eigenvalues of the Jacobian matrix at the fixed point $$A = \\begin{pmatrix}\n  \\frac{\\partial \\dot{x}}{\\partial x} \u0026\u0026 \\frac{\\partial \\dot{x}}{\\partial y} \\\\\n  \\frac{\\partial \\dot{y}}{\\partial x} \u0026\u0026 \\frac{\\partial \\dot{y}}{\\partial y}\n  \\end{pmatrix}$$\n\t- Once you have found this matrix, plug in $(x^\\*, y^\\*)$ and find the eigenvalues\n- these eigenvalues can be found by taking the trace $\\tau$ and determinant $\\Delta$ of $A$ $$\\begin{split} \n  \\tau \u0026= a + b \\\\\n  \\Delta \u0026 = ad-bc\n  \\end{split}$$ and plugging these values into the quadratic equation$$\\lambda_{1,2} = \\frac{\\tau \\pm \\sqrt{\\tau^2 - 4\\Delta}}{2}$$\n- There are a few cases that these fixed points can have based on their eigenvalues. When the eigenvalues are purely real and distinct ($\\lambda_1 \\neq \\lambda_2$, $\\tau^2 - 4 \\Delta \u003e 0$) we have\n\t- if $\\lambda_1, \\lambda_2 \u003e 0$ **stable node**\n\t- if $\\lambda_1, \\lambda_2 \u003c 0$ **unstable node**\n- if the eigenvalues are of opposite sign, the fixed point is a saddle\n\tIn all of these cases, the trajectories become parallel with the eigendirection (span of eigenvector) of greatest norm. When the eigenvalues are complex ($\\tau^2 - 4 \\Delta \u003c 0$) \n\t- if the eigenvalues are complex but not purely imaginary ($\\tau \\neq 0$) the fixed point is a **spiral** with stability found by analyzing the sign of the real componant\n\t\t- if the eigenvalues are purely imaginary ($\\tau = 0$) the fixed point is a **centre**, with a family of closed obits around it (these orbits are never attractors or repellers, each trajectory stays isolated in its original closed orbit)\n- If $\\lambda_1 = \\lambda_2$ there is only one eigenvalue, and there are new cases\n\t- if there are still 2 eigenvectors, every vector is an eigenvector with the same eigenvalue and the fixed point is a **star**, stable if $\\lambda \u003c 0$, unstable if $\\lambda \u003e 0$ \n\t\t- if there is only one eigenvector, the fixed point is a **degerate node** and all trajectories become parallel with this single eigendirection\n### Borderline cases for linear stability analysis-referring to nonlinear terms\n- For the borderline cases (centres, stars, nodes, i.e. when there are not two eigenvalues of distinct magnitude), the conclusions of linear stability analysis can turn out to be wrong when considering nonlinear terms\n\t- For stars and nodes, stability does not change, but for centres it can\n\t\t- this can be resolved by tranforming into polar coordinates and seeing if the radius is increasing or decreasing monotonically with time. If this is true, the point is a spiral\n### Conservative systems\n- Systems for which there is a conserved quantity\n- based on the conservation of energy\n- A conservative system has a conserved quantity (a function $E(\\vec{x})$) that is constant on trajectories, but not constant on any open set\n- this implies that the system cannot have any attracting points\n- conservative systems have a way of asserting that a nonlinear centre is truly a centre. \n\t- if a system has a conserved quantity, and stability analysis says its a centre, than it is a centre even when considering nonlinear terms\n\t- if the fixed point $\\vec{x}^\\*$ is a local miniumun of $E$ then all trajectories sufficiently close to $\\vec{x}^\\*$ are closed\n### Homoclinic Orbits\n- trjectories that begin and end at the same fixed point\n- take infinite time to leave, and to return\n### Reversible systems\n- have time-reversal symmetry\n\t- the dynamics look the same if time runs forwards or backwards \n- more specifically, a reversible system is any 2nd order system that is invariant under $t \\rightarrow -t$ and $y \\rightarrow -y$ \n\t- For example, any system where $$\\begin{cases}\n\t  \\dot{x} \u0026= f(x,y) \\\\\n\t  \\dot{y} \u0026 = g(x,y)\n\t  \\end{cases}$$ where $f$ is odd and $g$ is even (i.e. $f(x, -y) = -f(x,y)$ and $g(x, -y) = g(x,y)$\n- reversable systems are different from conservative systems, but showing that a system is reversible is enough to show that a nonlinear centre exists\n- effectively, reversability is being symmetric across the $x$-axis\n### Heteroclinic trajectory or Saddle Connection\n- a trajectory directly between two saddle points\n- more common in reversible or conservative systems\n- also takes infinite time to arrive and leave\n### Index of a curve\n- The index of a curve is $I_o = \\frac{1}{2 \\pi} [\\varphi]_C$ \n\t- $[\\phi]_C$ is the sum of the differences between the angles relative to the horizontal of any vector that passes through a simply connected closed curve on a continuously differentiable vector field $\\dot{\\vec{x}} = \\vec{f}vec{x})$ that passes through no fixed points (call this angle $\\varphi$)\n\t- the index is always an integer value, since $[\\varphi]_C$ must rotate back to itself\n- Properties of the Index of a Curve\n\t- If $C$ can be continuously deformed into $C'$ (i.e. deformed without crossing any fixed points) then $I_C = I'_C$ \n\t\t- this is because any continuous integer function must be constant\n\t- If $C$ contains no fixed points, then $I_C = 0$\n\t\t- this is because any difference must return to the same point without fully rotating.\n\t- If we reverse all arrows in $f$ by reversing time $t \\rightarrow -t$ then the index is unchanged\n\t\t- This is because reversing time is equivalent to the translation $\\varphi \\rightarrow \\varphi + \\pi$ and we are taking the sum of differences, which is unchanged by such a transformation\n\t- If $C$ is a trajectory of the system, then $I_c = +1$\n\t\t- this is because the flow follows the path of $C$ if $C$ is a trajectory\n\t- If we subdivide $C = C_1 + C_2$, then its index is the sum of the indicies of the curves $I_C = I_{C_1} + I_{C_2}$ \n\t\t- this is because the overlapping sections of the curves are equal and opposite, and thus cancel out.\n### Index of a point\n- the index of a curve that includes only one fixed point $\\vec{x}^*$ \n\t- if $\\vec{x}^*$ is a stable or unstable node, or a spiral, or a centre, $I_C = +1$\n\t- if $\\vec{x}^*$ is a saddle, $I_C = -1$\n### Index of a curve enclosing $n$ fixed points\n- If $C$ ncloses $n$ fixed points $x_1^\\*, x_2^\\*, ... , x_n^\\*$, then $I_C = I_1 + I_2 + ... + I_n$ \n\t- this is because any arbitrarily small curves around non-fixed points have $I_C = 0$, meaning only the curves enclosing fixed points constribute. Then by the additive property, we take the sum.\n## Limit Cycles and building up to Chaos\n### Limit Cycle\n- A limit cycle is an isolated closed trajectory\n- neighbouring trajectories spiral into or out of limit cycles\n- If a system has a limit cycle, it settles into a self-sustained oscillations for large $t$\n### Gradient systems\n- A gradient system is a system that can be written as $\\dot{\\vec{x}} = - \\nabla V$ Where $V(\\vec{x})$ is a continuous single valued scaler function\n- limit cycles are impossible on gradient systems\n### Liapunov Functions\n- A Liapunov function is a continuously differentiable, real valued function $V(\\vec{x})$ where\n\t- $V(\\vec{x})\u003e0$ for all $\\vec{x} \\neq \\dot{\\vec{x}}$, and $V(\\vec{x}^\\*) = 0$ (positively definate)\n\t- $\\dot{V} \u003c 0$ for all $\\vec{x} \\neq \\vec{x}^*$ (all trajectories flow toward $\\vec{x}^\\*$) \n- If a liapunov function is found for a fixed point, it must be globally asymptotically stable for all initial conditions $\\vec{x}(t) \\rightarrow \\vec{x}^*$ and thus the system must have no closed orbits \n- requires divine inspiration to find Liapunov functions\n### Dulac's Criterion\n- Dulac's criterion is a theorem for ruling out closed orbits using green theorem, and is as follows\n\t- Let $\\dot{\\vec{x}} = \\vec{f}(\\vec{x})$ be a continuously differentiable vector field on a simply connected subset of the plane $R$\n\t- If there exists a continuously differentiable, real valued function $g(\\vec{x})$ such that $\\nabla \\cdot g(\\vec{x})$has one definate sign throughout $R$, then there are no closed orbits through $R$\n- requires divine inspiration to find $\\vec{g}$ \n\t- sometimes $g = 1, \\frac{1}{x^a y^b}, e^{ay}$ work\n### Poincaré-Bendixson theorem\n- Allows us to verify that closed limit cycles exist, as well as that chaos cannot exist on the phase plane.\n- Consider the following conditions\n\t- $\\dot{\\vec{x}} = \\vec{f}(\\vec{x})$ be a continuously differentiable vector field on a subset of the plane $R$ \n\t- $R$ is closed and bounded\n\t- $R$ contains no fixed points\n\t- There exists some trajectory $C$ that is confined to $R$ for all time (i.e. starts in $C$ and never leaves)\n- If all of these criteria are met, $C$ is either a closed orbit or it spirals into a closed orbit as $t \\rightarrow \\infty$ \n- Since this trajectory cannot pass over itself in 2D, it must settle into a closed orbit\n\t- this implies there is no chaos in the phase plane\n- Does not apply in 3-D since trajectories can wander around and settle into a strange attractor\n### Bifurcations in 2-D\n- A bifurcation is a change in the structure of the phase portrait\n\t- a change in the number and location of fixed points, closed orbits, or saddle connections as the control parameters change\n### Saddle Bifurcation\n- Prototype: $$\\begin{cases}\n  \\dot{x} \u0026= \\mu - x^3 \\\\\n  \\dot{y} \u0026 = -y\n  \\end{cases}$$ if we take $\\mu \u003e 0$, we can see that there is a sable node at $(\\sqrt{\\mu}, 0)$ and a saddle at $(-\\sqrt{\\mu}, 0)$ As $\\mu$ is decreased, these fixed points merge at $\\mu = 0$ and then vanish for $\\mu \u003c 0$\n### Transcritical \u0026 pitchfork bifurcations\n- act similarly to their 1-D counterparts, just with $\\dot{y}= -y$ added\n### Hopf Bifurcations\n- Hopf Bifurcations are bifurcations where a stable fixed point with two complex-conjugate eigenvalues loses its stability by simultaneously having the real componants of their eigenvalues go from being negative to being positive.\n- (important and subtle) For this to happen, the eigenvalues must have nonzero real componants, and thus can only be spirals and not centres \n- Hopf Bifurcations can be **supercritical**, **subcritical**, or **degenerate**\n### Supercritical Hopf Bifurcation\n- A supercritical Hopf bifurcaiton is a bifurcation that takes a fixed point that is a stable spiral and turns it into an unstable spiral being orbited by a small, nearly elliptical limit cycle\n- can occur in any dimension $n \\geq 2$ \n- prototype: $$\\begin{cases}\n  \\dot{r} \u0026 = \\mu r -r^3 \\\\\n  \\dot{\\theta} \u0026= \\omega+br^2\n  \\end{cases}$$\n\t- for $\\mu\u003c0$ the origin is a stable spiral with a direction depending on $\\omega$. \n\t- for $\\mu = 0$ the origin is a weak stable spiral (linear stability analysis would call it a centre)\n\t- for $\\mu \u003e 0$ the origin is an unstable spiral with a stable circular limit cycle at $r = \\sqrt{\\mu}$ \n- There are some attributes that are _generically_ true\n\t- the limit cycle grows continuosly from the origin an increases proportional to $\\sqrt{\\mu - \\mu_c}$ for $\\mu$ close to $\\mu_c$ \n\t- the frequency of oscillation is approximately $\\omega = \\text{Im}(\\lambda)$ evaluated at $\\mu=\\mu_c$\n\t\t- this is exact at the limit cycle and correct within $O(\\mu-\\mu_c)$\n\t\t- this means the period is $T = \\frac{2 \\pi}{\\text{Im}(\\lambda)} + O(\\mu-\\mu_c)$\n### Subcritical Hopf Bifurcation\n- A subcritical Hopf Bifurcation is where an unstable spiral surrounded by a stable limit cycle becomes an unstable limit limit cycle surrounded by a larger stable limit cycle, both of which surround a stable spiral. A trajectory will jump like in a subcritical pitchfork bifurcation, and will exhibit hysteresis\n- prototype: $$\\begin{cases}\n  \\dot{r} \u0026 = \\mu r -r^3-r^5 \\\\\n  \\dot{\\theta} \u0026= \\omega+br^2\n  \\end{cases}$$\n\t- if $\\mu \u003c 0$ there is a stable spiral at the origin surrounded by an small unstable limit cycle, surrounded by a larger stable limit cycle\n\t- if $\\mu = 0$ the unstable limit cycle has shrunk in radius and merged with the origin, turning it into an unsable spiral\n\t- if $\\mu \u003e 0$ the origin is an unstable spiral and the only stable attractor is the larger limit cycle\n- This system exhibits **hysteresis** in that when $\\mu$ is increased over 0, the particles that go to it will not return to the origin even if the origin regains stability\n### Degenerate Hopf Bifurcation\n- A degenerate Hopf Bifurcation is a Hopf Bifurcation where a stable spiral transitions into a family of concentric closed orbits, and then into an unstable limit cycle\n\t- consider the damped pendulum $\\ddot{x} + \\mu \\dot{x} + \\sin x = 0$ \n\t\t- if $\\mu \u003e0$ the origin is a stable spiral\n\t\t- if $\\mu = 0$ the origin is a centre surrounded by a family of closed orbits (making this not quite a true Hopf Bifurcation)\n\t\t- if $\\mu \u003c 0$ the origin is an unstable spiral\n- Degenerate Hopf Bifurcations typically happen when a nonconservative system suddenly becomes conservative at $\\mu_c$. In this case, the origin becomes a nonlinear centre rather than the weak spiral required by a Hopf Bifurcation\n### Saddle-Node Bifurcation of Cycles\n- A saddle-node bifurcation of lmit cycles is where two limit cycles coalesce and annihilate\n- Prototype: $$\\begin{cases}\n  \\dot{r} \u0026= \\mu r + r^3 - r^5 \\\\\n  \\dot{\\theta} \u0026= \\omega + br^2\n  \\end{cases}$$\n- the projection onto the $(r, \\dot{r})$ plane looks like a saddle-node bifurcation in the region of the plane\n\t- for $\\mu \u003c \\mu_c$ there is a stable spiral towards the fixed point\n\t- at $\\mu = \\mu_c$ a half-stable limit cycle appeears\n\t- for $0 \u003e \\mu \u003e \\mu_c$ the half stable cycle splits into an smaller amplitude unstable cycle and a larger amplitude stable cycle\n\t- The origin remains a stable spiral in all cases\n### Infinite Period Bifurcations\n- An infinite period bifurcation is where a stable limit cycle slows down until a fixed point emerges and the limit cycle has an infite period\n- Prototype: $$\\begin{cases}\n  \\dot{r} \u0026= r(1-r^2) \\\\\n  \\dot{\\theta} \u0026= \\mu- \\sin\\theta\n  \\end{cases}$$\n\t- for $\\mu \u003e 1$ the trajectory slows down in the neighbourhood of $\\theta = \\pi/2$ as $\\mu$ is decreases\n\t- at $\\mu=1$ a semi-stable fixed point emerges and the time needed to traverse the whole limit cycle becomes infinite (hence the name)\n\t- for $\\mu \u003c 1$ the semi-stable fixed point splits into a saddle and a stable node that seperate along the trajectory, each trajectory taking infinite time to traverse\n### Homoclinic Bifurcations\n- Homoclinic Bifurcations are a sub-class of homoclinic Bifurcations\n- Homoclinic bifurcations occur when a limit cycle approaches a saddle point, making a homoclinic orbit\n- Prototype: $$\\begin{cases}\n  \\dot{x} \u0026= y \\\\\n  \\dot{y} \u0026= \\mu y + x - x^2 + xy\n  \\end{cases}$$\n\t- For $\\mu \u003c \\mu_c$ there is a saddle point at the origin, and a stable limit cycle orbiting an unstable spiral at $x=1$ with increasing amplitude as $\\mu$ is increases\n\t- at $\\mu = \\mu_c$ the limit cycle touches the saddle point and becomes a homoclinic orbit\n\t- for $\\mu \u003e \\mu_c$ the limit cycle is destroyed\n### Quasiperiodicity\n- A quasiperiodic flow is a flow that endlessly winds around a phase space, never intersecting itself, but also never closing\n- quasiperiodic flows are dense\n\t- each trajectory comes arbitrarily close to any given point on the torus\n- prototype: uncoupled oscillators with the form $\\dot{\\theta}_1 = \\omega_1, \\dot{\\theta}_2 = \\omega_2$ where $\\omega_1/\\omega_2$ is irrational\n### Pointcaré maps\n- Take $S$ to be an $n-1$ dimensional surface that is transverse to the flow (i.e. all trajectories starting on $S$ flow through it)\n- the Pointcaré map $P$ makes from $S$ to itself where if $x_k \\in S$ then $x_{k+1} = P(x_k)$ \n## Chaos\n### Lorenz System/equations\n- the set of equations following the form $$\\begin{cases}\n  \\dot{x} \u0026= \\sigma (y-x) \\\\\n  \\dot{y} \u0026= rx-y-xz \\\\\n  \\dot{z} \u0026= xy-bz\n  \\end{cases}$$ where $\\sigma, r, b\u003e0$ are parameters\n- the lorenz equations perfectly model a Malkus waterwheel, as well as being present in lasers, dynamos, and a simple model of convection rolls in the atmosphere\n- has a fractal phase space\n- prototype of chaos\n### Liapunov exponant\n- the Liapunov exponant $\\lambda$ is a measure of the rate that two trajectories on an attractor diverge (the difference is $\\delta(t)$)\n\t- $||\\delta(t)|| \\approx ||\\delta_0|| e^{\\lambda t}$ \n- A requirement for an attractor to be strange is that it must have a positive Liapunov exponant (i.e. any two trajectories should diverge exponantially with time)\n- the term is sloppy because:\n\t- an $n$-dimensional system has $n$ Liapunov exponants. Our $\\lambda$ is actually the largest of these exponants\n\t- $\\lambda$ depends on which trajectory we study, leading to inconclusive results in certain cases\n### Chaos\n- Chaos is an aperiodic long term behaviour in a deterministic system that exhibits a sensitive dependence on initial conditions\n\t- (aperiodic) trajectories do not settle down to fixed points, periodic orbits, or quasiperiodic orbits at $t\\rightarrow \\infty$. These trajectories should occur with nonzero probability (within a set of random initial conditions) or within an open set of initial conditions\n\t- (determistic) the irregular behaviour arises from the system's nonlinearity rather than noisy inputs or driving forces\n\t- (sensitive to initial conditions) neighbouring trajectories seperate exponentially fast (the system has a positive liapunov exponant)\n### Attractor\n- An attractor is a closed set $A$ with the following properties\n\t- A is an invariant set\n\t\t- a point that starts in $A$ stays in $A$ for all time\n\t- $A$ attracts an open set of initial conditions\n\t\t- define the open set $U$ where for any initial condition $\\vec{x}(0)$ the distance from $\\vec{x}(t)\\rightarrow 0$ as $t \\rightarrow \\infty$ \n\t- $A$ is minimal\n\t\t- there is no proper subset of $A$ that satisfies the first two conditions\n### Strange Attractor\n- A strange attractor is an attractor that exhibits a sensitive dependence on initial conditions (i.e. trajectories that fall into it are chaotic)\n### Maps\n- An iterated map is a discrete function where $x_{k+1} = f(x_k)$ \n- a sequene of a map $x_1, x_2, ... , x_n$ is called an orbit\n- useful for\n\t- analyzing differential equations (e.g. Poincaré maps)\n\t- modelling natural phenomena with discrete timesteps and non-overlapping generations\n\t- simple examples of chaos\n### Stability of Maps\n- $x^\\*$ is a fixed point if $x_{n+1} = f(x_n) = x_n = x^\\*$ \n- the equialent of an eigenvalue for a map is the **multiplier** $\\lambda = f'(x)$ \n\t- if $|\\lambda| \u003c 1$ the point is **linearly stable**\n\t- if $|\\lambda| \u003e 1$ the point is **unstable**\n\t- if $|\\lambda| = 1$ the point is **marginal** and has its stability determined by higher order terms\n\t- if $\\lambda = 0$ the point is **superstable**\n\n## Concepts with Derrivations\n","lastmodified":"2022-12-16T00:21:59.098376735Z","tags":null},"/notes/jc-tattoo-inspo":{"title":"Tattoo Documentation for Jess","content":"\n## Placement\nI'm thinking on my right arm or right leg. I'd be very interested in pieces that work well with motion, preferably spanning two joints.\n\n## Previous tattoos\n\nThese are tattoos that are of the style I'd be interested in (I wanted to embed the images, but Instagram is being painful with how to retrieve links to images)\n\n\u003ehttps://www.instagram.com/p/CZhlsnpO7I5/\n\u003e\tI love the way leaves fold over each other here\n\u003ehttps://www.instagram.com/p/CXL7ZtmrIDw/\n\u003e\tyou have a lot of pieces like this, that work very well in motion, which I am also very interested in. More examples here. \n\u003e\t1. https://www.instagram.com/p/CflxGjCuWww/\n\u003e\t2. https://www.instagram.com/p/Ce1trp9vlLg/\n\u003e\t3. https://www.instagram.com/p/CdnvNfAuGBJ/\n\u003e\t4. https://www.instagram.com/p/CVk7RNerGs2/\n\u003ehttps://www.instagram.com/p/CVDhmx-grT8/\n\u003e\tthis piece has a lot of fine detail work, which I'm tempted by, since it gives room for some of the self-organizing patters discussed below\n\u003ehttps://www.instagram.com/p/Cj5sjIYu5cT/\n\tI also absolutely love when the leaves twist around themselves and make helicies, like this example\n\n## Forms from Complexity: Self-Similarity and Self-Organization\n\nOne hallmark of self-organized systems, or moments of spontaneous order is self-similarity. Essentially, this means that there is some fractal behavior present. An example of this is the mandelbrot set.\n\n![Feigenbaumzoom.gif](images/Feigenbaumzoom.gif)\n\nYou can see that as the image zooms in, the structure of the pattern is maintained. Similar happens with a Koch Curve. \n\n![KochSnowGif16_800x500_2.gif](images/KochSnowGif16_800x500_2.gif)\n\nMany living systems exhibit self-similar behavior. This is a romenesco cauliflower\n\n![roma-cal.png](https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Flickr_-_cyclonebill_-_Romanesco.jpg/1600px-Flickr_-_cyclonebill_-_Romanesco.jpg)\n\nNotice that the small knobs exhibit the same behavior as the whole head of the cauliflower, and the knobs on each knob follow that same pattern as well. \n\nAnother famous example of self-similarity in plants is in ferns. This is a mathematical diagram called the Barnsley Fern.\n\n![Fractal_fern_explained.png](images/Fractal_fern_explained.png)\n\nReal ferns are self-similar in slightly less perfect ways, but still self-similar. Here are some examples\n\n![fiddlehead-2.jpeg](images/fiddlehead-2.jpeg) \n\nNot only the central branch coils up, but also the smaller 'leaf' branches as well. This image is not particularly fractal, but demonstrates this leaf-coiling well.\n\n![fiddlehead-3.jpeg](images/fiddlehead-3.jpeg)\n\nHere is a photo of a fern that I took in pacific spirit park, near my home in Vancouver. Notice how the leaves are little ferns in themselves.\n\n![van-fern.png](images/van-fern.png)\n\nOr, also in my neighborhood at home, the branches of trees exhibit fractal branching patterns\n\n![van-snow-branches.png](images/van-snow-branches.png)\n\nLichens also exhibit some of the most incredible fractal behavior. This is another example found on the underside of a tree in Vancouver.\n\n![van-lichen.png](images/van-lichen.png)\n\nOr, in much more incredible fashion, these are lichens from Meare's island close to Tofino, one of the last untouched old growth forests in Canada. These lichens are likely hundreds of years old\n\n![meares-lichen.png](images/meares-lichen.png)\n\nAt this level, they really start to take alien form, like plants from a different planet.\n\nI'm absolutely not expecting all (or any) of these fractal points to end up in my tattoo. If it could, I think it would be super cool, but I also imagine it would take a lot of work. I got a little carried away once I started looking into it, but I think it super cool and pretty.\n","lastmodified":"2022-12-16T00:21:59.098376735Z","tags":null},"/notes/levin-reading-notes":{"title":"levin-reading-notes","content":"# The Biophysics of Regenerative Repair Suggests New Perspectives on Biological Causation (M. Levin, 2020)\n- Anatomical “macrostates” can be implemented by a wide range of molecular and cellular arrangements and even time-series trajectories that all implement the same large-scale outcomes.[5–7]\n- Artificial Life in silico and in vitro[15]\n- It is impossible here to do justice to the rich literature on causation in biology, and philosophically inclined readers are invited to delve deeper.[11,14,21–35]\n- [relevant causation is] a mechanism or event is the cause of some outcome when it provides the most efficient way for experimenters, or the biological system itself, to induce it to occur, prevent it from occurring, or modify how it occurs.\n- There has been a rich debate in philosophy and science about the nature of causation,[6,8,12,13]\n- Any set of components will give rise to some emergent electrical pattern (akin to turing pattern self-organization from a homogenous substrate[80]), but if the components and their connectivity map has been subject to selection, it will give rise to electrical dynamics that are robust, process inputs into useful outputs, and in some cases can even implement memory (subsequent activity is modified by past experiences or input signals)\n- genetic descriptions belief that morphodynamics are based on linear gene expression\n\t- this should lead to errors propogating downstream\n- these errors in fact reduce in frequency downstream\n\t- the model must be incomplete\n- behaviors are not based on states of local environment\n\t- if you graft the tail of salamander onto the place where a tail should be, it slowly turns into an arm\n- picasso tadpoles\n\t- even if you put all the parts of a tadpole in the wrong place, they take unorthodox paths towards the correct position as they metamorphasize into frogs\n\t\t- morphology is not a linear execution of experiements, but rather governed by attractors seeking stable states\n\t\t\t- via dynamical systems theory\n- [A teleological] perspective offers an important and practical strategy for bioengineers: re-writing the stored setpoint (and letting un-modified cells build to that new specification), instead of attempting to micromanage (re-wire) individual cell interaction rules, hoping emergence of desired largescale outcomes.\n\n","lastmodified":"2022-12-16T00:21:59.098376735Z","tags":null}}